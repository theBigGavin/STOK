# æ•°æ®åº“ç¯å¢ƒéªŒè¯å’Œæµ‹è¯•æ–‡æ¡£

## 1. éªŒè¯æµç¨‹æ¦‚è¿°

### 1.1 éªŒè¯ç›®æ ‡

ç¡®ä¿æ•°æ®åº“ç¯å¢ƒæ­å»ºå®Œæ•´ã€æ•°æ®ä¸€è‡´ã€æ€§èƒ½è¾¾æ ‡ï¼ŒåŒ…æ‹¬ï¼š

- æ•°æ®åº“æœåŠ¡å¥åº·çŠ¶æ€
- æ•°æ®è¡¨ç»“æ„å’Œçº¦æŸ
- æµ‹è¯•æ•°æ®å®Œæ•´æ€§
- è¿æ¥æ€§èƒ½å’Œç¨³å®šæ€§
- å¤‡ä»½æ¢å¤åŠŸèƒ½

### 1.2 éªŒè¯é˜¶æ®µ

| é˜¶æ®µ     | éªŒè¯å†…å®¹           | æ‰§è¡Œæ—¶æœº   |
| -------- | ------------------ | ---------- |
| ç¯å¢ƒéªŒè¯ | æœåŠ¡å¥åº·ã€è¿æ¥æµ‹è¯• | ç¯å¢ƒæ­å»ºå |
| ç»“æ„éªŒè¯ | è¡¨ç»“æ„ã€ç´¢å¼•ã€çº¦æŸ | è¿ç§»å®Œæˆå |
| æ•°æ®éªŒè¯ | æ•°æ®å®Œæ•´æ€§ã€ä¸€è‡´æ€§ | ç§å­æ•°æ®å |
| æ€§èƒ½éªŒè¯ | æŸ¥è¯¢æ€§èƒ½ã€è¿æ¥æ±    | ç³»ç»Ÿè¿è¡Œå‰ |
| é›†æˆéªŒè¯ | åº”ç”¨é›†æˆã€API è°ƒç”¨ | éƒ¨ç½²å®Œæˆå |

## 2. ç¯å¢ƒéªŒè¯è„šæœ¬

### 2.1 æœåŠ¡å¥åº·æ£€æŸ¥ (health_check.py)

```python
#!/usr/bin/env python3
"""
æ•°æ®åº“æœåŠ¡å¥åº·æ£€æŸ¥è„šæœ¬
"""

import asyncio
import logging
import sys
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HealthChecker:
    """å¥åº·æ£€æŸ¥å™¨"""

    def __init__(self):
        self.checks = []
        self.start_time = datetime.now()

    def add_check(self, name, check_func):
        """æ·»åŠ æ£€æŸ¥é¡¹"""
        self.checks.append({"name": name, "func": check_func})

    async def check_postgres(self):
        """æ£€æŸ¥ PostgreSQL æœåŠ¡"""
        try:
            from backend.src.config.database import db_config
            engine = db_config.create_engine()

            async with engine.connect() as conn:
                # æ£€æŸ¥ç‰ˆæœ¬
                result = await conn.execute("SELECT version()")
                version = result.scalar()

                # æ£€æŸ¥è¿æ¥æ•°
                result = await conn.execute("SELECT count(*) FROM pg_stat_activity")
                connections = result.scalar()

                # æ£€æŸ¥æ•°æ®åº“å¤§å°
                result = await conn.execute("""
                    SELECT pg_size_pretty(pg_database_size('stock_system'))
                """)
                db_size = result.scalar()

                await conn.close()

            logger.info(f"PostgreSQL ç‰ˆæœ¬: {version.split(',')[0]}")
            logger.info(f"å½“å‰è¿æ¥æ•°: {connections}")
            logger.info(f"æ•°æ®åº“å¤§å°: {db_size}")

            return True
        except Exception as e:
            logger.error(f"PostgreSQL æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def check_redis(self):
        """æ£€æŸ¥ Redis æœåŠ¡"""
        try:
            from backend.src.config.redis_config import redis_config
            client = await redis_config.get_redis_client()

            # æ£€æŸ¥è¿æ¥
            ping_result = await client.ping()

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            info = await client.info("memory")
            used_memory = info.get("used_memory_human", "N/A")

            # æ£€æŸ¥é”®æ•°é‡
            key_count = await client.dbsize()

            await client.close()

            logger.info(f"Redis Ping: {ping_result}")
            logger.info(f"Redis å†…å­˜ä½¿ç”¨: {used_memory}")
            logger.info(f"Redis é”®æ•°é‡: {key_count}")

            return True
        except Exception as e:
            logger.error(f"Redis æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def check_database_tables(self):
        """æ£€æŸ¥æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            from backend.src.config.database import db_config
            from sqlalchemy import inspect

            engine = db_config.create_engine()

            async with engine.connect() as conn:
                inspector = inspect(engine)
                tables = inspector.get_table_names()

                required_tables = [
                    'stocks', 'stock_daily_data', 'backtest_models',
                    'model_decisions', 'final_decisions', 'model_performance'
                ]

                missing_tables = []
                for table in required_tables:
                    if table not in tables:
                        missing_tables.append(table)

                if missing_tables:
                    logger.error(f"ç¼ºå°‘è¡¨: {missing_tables}")
                    return False

                logger.info(f"æ‰€æœ‰å¿…éœ€è¡¨å­˜åœ¨: {required_tables}")

                # æ£€æŸ¥è¡¨è®°å½•æ•°
                for table in required_tables:
                    result = await conn.execute(f"SELECT COUNT(*) FROM {table}")
                    count = result.scalar()
                    logger.info(f"è¡¨ {table} è®°å½•æ•°: {count}")

                await conn.close()

            return True
        except Exception as e:
            logger.error(f"è¡¨ç»“æ„æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def check_data_integrity(self):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        try:
            from backend.src.config.database import db_config

            engine = db_config.create_engine()

            async with engine.connect() as conn:
                # æ£€æŸ¥å¤–é”®çº¦æŸ
                integrity_checks = [
                    # æ£€æŸ¥è‚¡ç¥¨æ—¥çº¿æ•°æ®çš„å¤–é”®
                    """
                    SELECT COUNT(*) FROM stock_daily_data sd
                    LEFT JOIN stocks s ON sd.stock_id = s.id
                    WHERE s.id IS NULL
                    """,
                    # æ£€æŸ¥æ¨¡å‹å†³ç­–çš„å¤–é”®
                    """
                    SELECT COUNT(*) FROM model_decisions md
                    LEFT JOIN stocks s ON md.stock_id = s.id
                    LEFT JOIN backtest_models bm ON md.model_id = bm.id
                    WHERE s.id IS NULL OR bm.id IS NULL
                    """,
                    # æ£€æŸ¥ç»¼åˆå†³ç­–çš„å¤–é”®
                    """
                    SELECT COUNT(*) FROM final_decisions fd
                    LEFT JOIN stocks s ON fd.stock_id = s.id
                    WHERE s.id IS NULL
                    """
                ]

                for i, check_sql in enumerate(integrity_checks):
                    result = await conn.execute(check_sql)
                    invalid_count = result.scalar()

                    if invalid_count > 0:
                        logger.error(f"å®Œæ•´æ€§æ£€æŸ¥ {i+1} å¤±è´¥: å‘ç° {invalid_count} æ¡æ— æ•ˆè®°å½•")
                        return False

                await conn.close()

            logger.info("æ‰€æœ‰æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def check_performance(self):
        """æ£€æŸ¥æ€§èƒ½åŸºå‡†"""
        try:
            from backend.src.config.database import db_config

            engine = db_config.create_engine()

            async with engine.connect() as conn:
                # ç®€å•æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
                start_time = datetime.now()

                # æµ‹è¯•å¤æ‚æŸ¥è¯¢
                test_queries = [
                    # æŸ¥è¯¢æœ€è¿‘äº¤æ˜“æ—¥çš„è‚¡ç¥¨æ•°æ®
                    """
                    SELECT s.symbol, s.name, sd.close_price, sd.volume
                    FROM stocks s
                    JOIN stock_daily_data sd ON s.id = sd.stock_id
                    WHERE sd.trade_date = (
                        SELECT MAX(trade_date) FROM stock_daily_data
                    )
                    ORDER BY sd.volume DESC
                    LIMIT 10
                    """,
                    # æŸ¥è¯¢æ¨¡å‹å†³ç­–ç»Ÿè®¡
                    """
                    SELECT m.name, COUNT(*) as decision_count,
                           AVG(md.confidence) as avg_confidence
                    FROM backtest_models m
                    JOIN model_decisions md ON m.id = md.model_id
                    WHERE md.trade_date >= CURRENT_DATE - INTERVAL '30 days'
                    GROUP BY m.id, m.name
                    ORDER BY decision_count DESC
                    """
                ]

                for i, query in enumerate(test_queries):
                    query_start = datetime.now()
                    result = await conn.execute(query)
                    rows = result.fetchall()
                    query_time = (datetime.now() - query_start).total_seconds()

                    logger.info(f"æŸ¥è¯¢ {i+1} æ‰§è¡Œæ—¶é—´: {query_time:.3f}ç§’, è¿”å› {len(rows)} è¡Œ")

                    if query_time > 5.0:  # 5ç§’é˜ˆå€¼
                        logger.warning(f"æŸ¥è¯¢ {i+1} æ‰§è¡Œæ—¶é—´è¿‡é•¿: {query_time:.3f}ç§’")

                total_time = (datetime.now() - start_time).total_seconds()
                logger.info(f"æ€§èƒ½æµ‹è¯•æ€»æ—¶é—´: {total_time:.3f}ç§’")

                await conn.close()

            return True
        except Exception as e:
            logger.error(f"æ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        logger.info("å¼€å§‹å¥åº·æ£€æŸ¥...")

        # æ·»åŠ æ£€æŸ¥é¡¹
        self.add_check("PostgreSQL", self.check_postgres)
        self.add_check("Redis", self.check_redis)
        self.add_check("è¡¨ç»“æ„", self.check_database_tables)
        self.add_check("æ•°æ®å®Œæ•´æ€§", self.check_data_integrity)
        self.add_check("æ€§èƒ½åŸºå‡†", self.check_performance)

        results = {}
        all_passed = True

        for check in self.checks:
            logger.info(f"æ‰§è¡Œæ£€æŸ¥: {check['name']}")
            try:
                result = await check['func']()
                results[check['name']] = result

                if result:
                    logger.info(f"âœ“ {check['name']} æ£€æŸ¥é€šè¿‡")
                else:
                    logger.error(f"âœ— {check['name']} æ£€æŸ¥å¤±è´¥")
                    all_passed = False

            except Exception as e:
                logger.error(f"âœ— {check['name']} æ£€æŸ¥å¼‚å¸¸: {e}")
                results[check['name']] = False
                all_passed = False

        # ç”ŸæˆæŠ¥å‘Š
        total_time = (datetime.now() - self.start_time).total_seconds()
        logger.info(f"å¥åº·æ£€æŸ¥å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

        if all_passed:
            logger.info("ğŸ‰ æ‰€æœ‰å¥åº·æ£€æŸ¥é€šè¿‡ï¼")
        else:
            logger.error("âŒ éƒ¨åˆ†å¥åº·æ£€æŸ¥å¤±è´¥")
            # è¾“å‡ºå¤±è´¥è¯¦æƒ…
            for check_name, passed in results.items():
                if not passed:
                    logger.error(f"  å¤±è´¥é¡¹: {check_name}")

        return all_passed

async def main():
    """ä¸»å‡½æ•°"""
    checker = HealthChecker()
    success = await checker.run_all_checks()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    asyncio.run(main())
```

## 3. è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

### 3.1 ç«¯åˆ°ç«¯æµ‹è¯• (e2e_test.py)

```python
#!/usr/bin/env python3
"""
æ•°æ®åº“ç¯å¢ƒç«¯åˆ°ç«¯æµ‹è¯•
"""

import asyncio
import logging
import random
from datetime import datetime, timedelta

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class E2ETester:
    """ç«¯åˆ°ç«¯æµ‹è¯•å™¨"""

    def __init__(self, db_session):
        self.db_session = db_session

    async def test_stock_operations(self):
        """æµ‹è¯•è‚¡ç¥¨ç›¸å…³æ“ä½œ"""
        logger.info("æµ‹è¯•è‚¡ç¥¨æ“ä½œ...")

        try:
            from sqlalchemy import select

            # æµ‹è¯•æŸ¥è¯¢è‚¡ç¥¨
            result = await self.db_session.execute(
                select(Stock).where(Stock.is_active == True).limit(5)
            )
            stocks = result.scalars().all()

            assert len(stocks) > 0, "æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒè‚¡ç¥¨"
            logger.info(f"æˆåŠŸæŸ¥è¯¢åˆ° {len(stocks)} åªè‚¡ç¥¨")

            # æµ‹è¯•æŸ¥è¯¢æ—¥çº¿æ•°æ®
            for stock in stocks:
                result = await self.db_session.execute(
                    select(StockDailyData)
                    .where(StockDailyData.stock_id == stock.id)
                    .order_by(StockDailyData.trade_date.desc())
                    .limit(1)
                )
                latest_data = result.scalar_one_or_none()

                if latest_data:
                    logger.info(f"è‚¡ç¥¨ {stock.symbol} æœ€æ–°ä»·æ ¼: {latest_data.close_price}")

            return True

        except Exception as e:
            logger.error(f"è‚¡ç¥¨æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_model_operations(self):
        """æµ‹è¯•æ¨¡å‹ç›¸å…³æ“ä½œ"""
        logger.info("æµ‹è¯•æ¨¡å‹æ“ä½œ...")

        try:
            from sqlalchemy import select, func

            # æµ‹è¯•æŸ¥è¯¢æ¨¡å‹
            result = await self.db_session.execute(
                select(BacktestModel).where(BacktestModel.is_active == True)
            )
            models = result.scalars().all()

            assert len(models) > 0, "æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒæ¨¡å‹"
            logger.info(f"æˆåŠŸæŸ¥è¯¢åˆ° {len(models)} ä¸ªæ¨¡å‹")

            # æµ‹è¯•æ¨¡å‹å†³ç­–ç»Ÿè®¡
            for model in models:
                result = await self.db_session.execute(
                    select(func.count(ModelDecision.id))
                    .where(ModelDecision.model_id == model.id)
                )
                decision_count = result.scalar()

                logger.info(f"æ¨¡å‹ {model.name} å†³ç­–æ•°é‡: {decision_count}")

            return True

        except Exception as e:
            logger.error(f"æ¨¡å‹æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_decision_aggregation(self):
        """æµ‹è¯•å†³ç­–èšåˆåŠŸèƒ½"""
        logger.info("æµ‹è¯•å†³ç­–èšåˆ...")

        try:
            from sqlalchemy import select, func

            # æµ‹è¯•ç»¼åˆå†³ç­–æŸ¥è¯¢
            result = await self.db_session.execute(
                select(FinalDecision)
                .order_by(FinalDecision.trade_date.desc())
                .limit(10)
            )
            recent_decisions = result.scalars().all()

            for decision in recent_decisions:
                logger.info(
                    f"å†³ç­–æ—¥æœŸ: {decision.trade_date}, "
                    f"ä¹°å…¥ç¥¨: {decision.buy_votes}, "
                    f"æœ€ç»ˆå†³ç­–: {decision.final_decision}"
                )

            return True

        except Exception as e:
            logger.error(f"å†³ç­–èšåˆæµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_performance_metrics(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡åŠŸèƒ½"""
        logger.info("æµ‹è¯•æ€§èƒ½æŒ‡æ ‡...")

        try:
            from sqlalchemy import select

            # æµ‹è¯•æ¨¡å‹æ€§èƒ½æŸ¥è¯¢
            result = await self.db_session.execute(
                select(ModelPerformance)
                .order_by(ModelPerformance.backtest_date.desc())
                .limit(5)
            )
            performances = result.scalars().all()

            for perf in performances:
                logger.info(
                    f"å›æµ‹æ—¥æœŸ: {perf.backtest_date}, "
                    f"å‡†ç¡®ç‡: {perf.accuracy:.2%}, "
                    f"æ€»æ”¶ç›Š: {perf.total_return:.2%}"
                )

            return True

        except Exception as e:
            logger.error(f"æ€§èƒ½æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•...")

        tests = [
            ("è‚¡ç¥¨æ“ä½œ", self.test_stock_operations),
            ("æ¨¡å‹æ“ä½œ", self.test_model_operations),
            ("å†³ç­–èšåˆ", self.test_decision_aggregation),
            ("æ€§èƒ½æŒ‡æ ‡", self.test_performance_metrics),
        ]

        results = {}
        all_passed = True

        for test_name, test_func in tests:
            try:
                result = await test_func()
                results[test_name] = result

                if result:
                    logger.info(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    logger.error(f"âœ— {test_name} æµ‹è¯•å¤±è´¥")
                    all_passed = False

            except Exception as e:
                logger.error(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
                results[test_name] = False
                all_passed = False

        if all_passed:
            logger.info("ğŸ‰ æ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡ï¼")
        else:
            logger.error("âŒ éƒ¨åˆ†ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥")

        return all_passed

async def main():
    """ä¸»å‡½æ•°"""
    from backend.src.config.database import get_db_session

    async with get_db_session() as db_session:
        tester = E2ETester(db_session)
        success = await tester.run_all_tests()

    exit(0 if success else 1)

if __name__ == "__main__":
    # å¯¼å…¥æ•°æ®æ¨¡å‹
    from backend.src.models.database import (
        Stock, StockDailyData, BacktestModel,
        ModelDecision, FinalDecision, ModelPerformance
    )

    asyncio.run(main())
```

## 4. éƒ¨ç½²éªŒè¯æ¸…å•

### 4.1 é¢„éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®
- [ ] æ•°æ®åº“æœåŠ¡è¿è¡Œæ­£å¸¸
- [ ] è¿ç§»è„šæœ¬æ‰§è¡ŒæˆåŠŸ
- [ ] ç§å­æ•°æ®åŠ è½½å®Œæˆ
- [ ] å¥åº·æ£€æŸ¥å…¨éƒ¨é€šè¿‡
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•è¾¾æ ‡

### 4.2 éƒ¨ç½²åéªŒè¯æ¸…å•

- [ ] åº”ç”¨æœåŠ¡å¯åŠ¨æ­£å¸¸
- [ ] API æ¥å£å“åº”æ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥ç¨³å®š
- [ ] Redis ç¼“å­˜å·¥ä½œæ­£å¸¸
- [ ] å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ­£å¸¸
- [ ] ç›‘æ§æŒ‡æ ‡æ”¶é›†æ­£å¸¸

## 5. æ•…éšœæ’é™¤æŒ‡å—

### 5.1 å¸¸è§é—®é¢˜è§£å†³

1. **æ•°æ®åº“è¿æ¥å¤±è´¥**

   - æ£€æŸ¥ç¯å¢ƒå˜é‡ `DATABASE_URL`
   - éªŒè¯æ•°æ®åº“æœåŠ¡çŠ¶æ€
   - æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™

2. **è¿ç§»è„šæœ¬æ‰§è¡Œå¤±è´¥**

   - æ£€æŸ¥æ•°æ®åº“ç‰ˆæœ¬å…¼å®¹æ€§
   - éªŒè¯è¿ç§»è„šæœ¬è¯­æ³•
   - æ£€æŸ¥ä¾èµ–è¡¨æ˜¯å¦å­˜åœ¨

3. **æ•°æ®å®Œæ•´æ€§é”™è¯¯**

   - è¿è¡Œæ•°æ®éªŒè¯è„šæœ¬
   - æ£€æŸ¥å¤–é”®çº¦æŸ
   - é‡æ–°æ‰§è¡Œç§å­æ•°æ®

4. **æ€§èƒ½é—®é¢˜**
   - æ£€æŸ¥ç´¢å¼•æ˜¯å¦åˆ›å»º
   - ä¼˜åŒ–æŸ¥è¯¢è¯­å¥
   - è°ƒæ•´è¿æ¥æ± é…ç½®

### 5.2 ç´§æ€¥æ¢å¤æ­¥éª¤

1. åœæ­¢åº”ç”¨æœåŠ¡
2. å¤‡ä»½å½“å‰æ•°æ®åº“
3. å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
4. æ‰§è¡Œæ•°æ®æ¢å¤
5. é‡æ–°éƒ¨ç½²åº”ç”¨

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-16  
**ç»´æŠ¤è€…**: è´¨é‡ä¿è¯å›¢é˜Ÿ
